# 数据保留策略 - 快速开始指南

## 📋 目录
1. [快速评估](#快速评估)
2. [初始化设置](#初始化设置)
3. [日常使用](#日常使用)
4. [高级操作](#高级操作)
5. [常见问题](#常见问题)

---

## 🔍 快速评估

### 1. 检查当前数据量

```bash
# 执行数据库查询脚本
python scripts/check_data_size.py
```

或者直接在MySQL中执行：

```sql
-- 查看各表数据量和存储空间
SELECT 
    table_name,
    table_rows as '记录数',
    ROUND(data_length/1024/1024, 2) AS '数据大小(MB)',
    ROUND(index_length/1024/1024, 2) AS '索引大小(MB)',
    ROUND((data_length + index_length)/1024/1024, 2) AS '总大小(MB)'
FROM information_schema.tables
WHERE table_schema = 'botnet'
AND table_name LIKE 'botnet_%'
ORDER BY (data_length + index_length) DESC;

-- 查看数据时间分布
SELECT 
    '通信记录' as 表类型,
    MIN(communication_time) as 最早时间,
    MAX(communication_time) as 最新时间,
    DATEDIFF(MAX(communication_time), MIN(communication_time)) as 数据跨度天数,
    COUNT(*) as 总记录数,
    COUNT(*) / DATEDIFF(MAX(communication_time), MIN(communication_time)) as 日均记录数
FROM botnet_communications_mozi;
```

### 2. 查看推荐配置

```bash
python scripts/retention_manager.py --help
```

---

## 🚀 初始化设置

### 步骤1: 配置保留策略

编辑 `scripts/data_retention_config.py`：

```python
# 数据保留天数（根据需求调整）
HOT_DATA_DAYS = 30      # 热数据：1个月（推荐 30-90 天）
WARM_DATA_DAYS = 180    # 温数据：6个月（推荐 90-365 天）

# 归档配置
ENABLE_ARCHIVE = True   # 是否启用归档
ARCHIVE_BASE_PATH = "D:/botnet_archive"  # Windows路径
# 或
ARCHIVE_BASE_PATH = "/data/archive/botnet"  # Linux路径

# 清理配置
CLEANUP_ENABLED = True  # 是否启用自动清理
CLEANUP_BATCH_SIZE = 10000  # 每批删除数量
```

### 步骤2: 初始化数据库表结构

```bash
# 为所有通信记录表添加 'archived' 字段
python scripts/retention_manager.py --mode init
```

这会为以下表添加 `archived` 字段：
- `botnet_communications_mozi`
- `botnet_communications_asruex`
- `botnet_communications_andromeda`
- 等等...

### 步骤3: 测试运行（演练模式）

```bash
# 演练模式：查看会删除哪些数据，但不实际删除
python scripts/retention_manager.py --mode daily --dry-run
```

输出示例：
```
[演练模式] 预计清理: 1,234,567 条记录
  - mozi: 500,000 条
  - asruex: 300,000 条
  - andromeda: 434,567 条
```

---

## 📅 日常使用

### 方式1: 手动执行（推荐初期）

```bash
# 执行每日维护任务（实际删除数据）
python scripts/retention_manager.py --mode daily
```

### 方式2: 定时任务（推荐长期）

#### Windows定时任务

创建批处理脚本 `run_retention.bat`：

```batch
@echo off
cd /d D:\workspace\botnet\backend
python scripts\retention_manager.py --mode daily >> D:\logs\retention.log 2>&1
```

设置计划任务：
```powershell
# 每天凌晨2点执行
schtasks /create /tn "BotnetDataRetention" /tr "D:\workspace\botnet\backend\run_retention.bat" /sc daily /st 02:00 /ru SYSTEM
```

#### Linux定时任务

编辑crontab：
```bash
crontab -e
```

添加：
```cron
# 每天凌晨2点执行数据保留任务
0 2 * * * cd /path/to/botnet/backend && python scripts/retention_manager.py --mode daily >> /var/log/botnet/retention.log 2>&1
```

---

## 🔧 高级操作

### 归档历史数据

#### 归档指定月份
```bash
# 归档2024年1月的数据
python scripts/data_archiver.py --mode month --year 2024 --month 1
```

#### 批量归档
```bash
# 归档2024年1月到6月的所有数据
python scripts/data_archiver.py --mode range \
    --start-year 2024 --start-month 1 \
    --end-year 2024 --end-month 6
```

#### 查看归档文件
```bash
# 归档文件位置
ls -lh /data/archive/botnet/2024/01/

# 输出示例：
# mozi_communications_202401.parquet (156 MB)
# asruex_communications_202401.parquet (98 MB)
# ...
```

### 清理特定僵尸网络数据

```bash
# 清理 mozi 僵尸网络 60 天前的数据
python scripts/data_cleaner.py --mode custom --botnet-type mozi --days 60

# 演练模式
python scripts/data_cleaner.py --mode custom --botnet-type mozi --days 60 --dry-run
```

### 恢复归档数据

使用Python读取归档文件：

```python
import pandas as pd

# 读取Parquet归档文件
df = pd.read_parquet('/data/archive/botnet/2024/01/mozi_communications_202401.parquet')

print(f"归档记录数: {len(df)}")
print(df.head())

# 如果需要导回数据库
from sqlalchemy import create_engine

engine = create_engine('mysql+pymysql://user:pass@localhost/botnet')
df.to_sql('botnet_communications_mozi', engine, if_exists='append', index=False)
```

---

## ❓ 常见问题

### Q1: 保留多久的数据合适？

**推荐配置**：
- 小规模分析（仅实时监控）：**30天**
- 中规模分析（含历史趋势）：**90天**
- 大规模分析（含季度报告）：**180天**
- 威胁情报研究：**365天**

根据您的需求：**推荐 90-180 天**

### Q2: 归档后还能查询吗？

归档数据有3种访问方式：
1. **直接读取Parquet文件**（使用pandas/pyspark）
2. **导入ClickHouse/Elasticsearch**（用于大数据分析）
3. **临时恢复到MySQL**（用于临时查询）

### Q3: 数据删除后能恢复吗？

- 如果启用了归档（`ENABLE_ARCHIVE=True`），数据会先归档再删除，可从归档文件恢复
- 如果未启用归档，删除后**无法恢复**
- 建议：**始终启用归档**，或至少做好数据库备份

### Q4: 删除会影响性能吗？

分批删除设计避免了长时间锁表：
- 每批删除10,000条（可调整）
- 批次间延迟1秒（可调整）
- 建议在业务低峰期（凌晨）执行

### Q5: 如何调整保留天数？

编辑 `scripts/data_retention_config.py`：

```python
HOT_DATA_DAYS = 60  # 从30天改为60天
```

或者使用环境变量：
```bash
export HOT_DATA_DAYS=60
python scripts/retention_manager.py --mode daily
```

### Q6: 统计表（china_botnet_*, global_botnet_*）会删除吗？

**不会删除**。统计表数据量很小（几MB），且具有长期分析价值，建议永久保留。

### Q7: 节点表（botnet_nodes_*）会删除吗？

**不会删除**。节点表仅保留每个IP的最新信息，数据量小，建议保留。
但会将长时间无通信的节点标记为 `status='inactive'`。

### Q8: 如何监控归档和清理任务？

查看日志：
```bash
# Linux
tail -f /var/log/botnet/retention_manager.log

# Windows
type D:\logs\retention.log
```

查看报告：
```bash
# 报告文件位置
ls /var/log/botnet/reports/
```

---

## 📊 性能优化建议

### 1. 使用表分区（适合超大数据量）

```sql
-- 为通信记录表添加按月分区
ALTER TABLE botnet_communications_mozi
PARTITION BY RANGE (UNIX_TIMESTAMP(communication_time)) (
    PARTITION p202401 VALUES LESS THAN (UNIX_TIMESTAMP('2024-02-01')),
    PARTITION p202402 VALUES LESS THAN (UNIX_TIMESTAMP('2024-03-01')),
    PARTITION p202403 VALUES LESS THAN (UNIX_TIMESTAMP('2024-04-01')),
    ...
);

-- 删除旧分区（极快，不会锁表）
ALTER TABLE botnet_communications_mozi DROP PARTITION p202401;
```

### 2. 优化索引

删除旧数据后，重建索引：

```sql
OPTIMIZE TABLE botnet_communications_mozi;
```

### 3. 调整批量删除参数

根据服务器性能调整：

```python
# 高性能服务器
CLEANUP_BATCH_SIZE = 50000  # 每批5万条
CLEANUP_DELAY_SECONDS = 0   # 无延迟

# 低性能服务器
CLEANUP_BATCH_SIZE = 5000   # 每批5千条
CLEANUP_DELAY_SECONDS = 2   # 延迟2秒
```

---

## 🛠️ 快速命令参考

```bash
# === 初始化 ===
python scripts/retention_manager.py --mode init

# === 每日维护 ===
python scripts/retention_manager.py --mode daily                    # 实际执行
python scripts/retention_manager.py --mode daily --dry-run          # 演练模式

# === 手动归档 ===
python scripts/data_archiver.py --mode auto                         # 归档上个月
python scripts/data_archiver.py --mode month --year 2024 --month 1 # 指定月份

# === 手动清理 ===
python scripts/data_cleaner.py --mode auto                          # 使用默认天数
python scripts/data_cleaner.py --mode auto --days 60                # 清理60天前
python scripts/data_cleaner.py --mode auto --dry-run                # 演练模式

# === 添加archived字段 ===
python scripts/data_cleaner.py --mode add-column

# === 标记已归档数据 ===
python scripts/data_cleaner.py --mode mark-archived --botnet-type mozi
```

---

## 📞 需要帮助？

如果遇到问题：

1. **查看日志**：`/var/log/botnet/retention_manager.log`
2. **演练模式测试**：使用 `--dry-run` 参数
3. **备份数据**：删除前务必备份数据库
4. **分步执行**：先归档，验证成功后再清理

---

## ✅ 推荐实施路线图

### 第1周：准备和测试
- [ ] 评估当前数据量
- [ ] 确定保留策略（推荐90-180天）
- [ ] 配置归档路径
- [ ] 初始化表结构（添加archived字段）
- [ ] 演练模式测试

### 第2周：首次归档
- [ ] 手动归档最早的数据
- [ ] 验证归档文件完整性
- [ ] 测试从归档文件恢复数据

### 第3周：首次清理
- [ ] 演练模式预览清理
- [ ] 实际清理已归档数据
- [ ] 观察数据库性能变化

### 第4周：自动化部署
- [ ] 部署定时任务
- [ ] 设置日志监控
- [ ] 建立定期检查机制

**祝您使用顺利！** 🎉
