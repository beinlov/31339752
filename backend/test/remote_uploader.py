#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¿œç«¯æ—¥å¿—ä¸Šä¼ è„šæœ¬
éƒ¨ç½²åœ¨è¿œç«¯èœœç½æœåŠ¡å™¨ä¸Šï¼Œå¼‚æ­¥è¯»å–æ¯æ—¥æ—¥å¿—æ–‡ä»¶ï¼Œå»é‡åä¸Šä¼ åˆ°æœ¬åœ°æœåŠ¡å™¨

æ¶æ„è®¾è®¡:
- LogReader: å¼‚æ­¥æ—¥å¿—è¯»å–å™¨ï¼Œè´Ÿè´£è¯»å–æ¯æ—¥æ—¥å¿—æ–‡ä»¶
- IPProcessor: IPå¤„ç†å™¨ï¼Œè´Ÿè´£è§£æã€å»é‡å’Œç¼“å­˜IPæ•°æ®
- RemoteUploader: ä¸Šä¼ å™¨ï¼Œè´Ÿè´£å°†å¤„ç†åçš„æ•°æ®ä¸Šä¼ åˆ°æœ¬åœ°æœåŠ¡å™¨
"""

import asyncio
import aiofiles
import aiohttp
import time
import os
import sys
import json
import re
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Set, Tuple
import logging
from pathlib import Path
from collections import defaultdict

# ============================================================
# é…ç½®åŒºåŸŸ - è¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
# ============================================================

# æœ¬åœ°æœåŠ¡å™¨é…ç½®
LOCAL_SERVER_HOST = "your-local-server-ip"  # ä¿®æ”¹ä¸ºæœ¬åœ°æœåŠ¡å™¨çš„å…¬ç½‘IPæˆ–åŸŸå
LOCAL_SERVER_PORT = 8000

# APIå¯†é’¥ï¼ˆå¿…é¡»ä¸æœ¬åœ°æœåŠ¡å™¨çš„config.pyä¸­çš„API_KEYä¸€è‡´ï¼‰
API_KEY = "KiypG4zWLXqnREqGPH8L2Oh9ybvi6Yh4"

# åƒµå°¸ç½‘ç»œç±»å‹ï¼ˆæ ¹æ®å®é™…èœœç½ç±»å‹ä¿®æ”¹ï¼‰
BOTNET_TYPE = "ramnit"  # å¯é€‰: asruex, mozi, andromeda, moobot, ramnit, leethozer

# æ—¥å¿—æ–‡ä»¶é…ç½®ï¼ˆæ¯æ—¥æ—¥å¿—æ–‡ä»¶ï¼‰
LOG_DIR = "/home/ubuntu"  # æ—¥å¿—æ–‡ä»¶ç›®å½•
LOG_FILE_PATTERN = "ramnit_{date}.log"  # æ—¥å¿—æ–‡ä»¶å‘½åæ¨¡å¼ï¼Œ{date}ä¼šè¢«æ›¿æ¢ä¸ºYYYY-MM-DD

# å¤„ç†é…ç½®
UPLOAD_INTERVAL = 300  # ä¸Šä¼ é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤5åˆ†é’Ÿ
BATCH_SIZE = 500       # æ¯æ¬¡ä¸Šä¼ çš„æœ€å¤§IPæ•°é‡
MAX_RETRIES = 3        # ä¸Šä¼ å¤±è´¥é‡è¯•æ¬¡æ•°
RETRY_DELAY = 30       # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
READ_CHUNK_SIZE = 8192 # æ–‡ä»¶è¯»å–å—å¤§å°

# çŠ¶æ€æ–‡ä»¶ï¼ˆè®°å½•å¤„ç†çŠ¶æ€ï¼‰
STATE_FILE = "/tmp/uploader_state.json"
DUPLICATE_CACHE_FILE = "/tmp/ip_cache.json"  # IPå»é‡ç¼“å­˜æ–‡ä»¶

# IPç¼“å­˜é…ç½®
CACHE_EXPIRE_DAYS = 7  # IPç¼“å­˜è¿‡æœŸå¤©æ•°

# APIç«¯ç‚¹é…ç½®
API_ENDPOINT = "https://periotic-multifaced-christena.ngrok-free.dev"

# IPè§£æé…ç½®
IP_REGEX = re.compile(r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b')  # IPåœ°å€æ­£åˆ™è¡¨è¾¾å¼

# ============================================================
# æ—¥å¿—é…ç½®
# ============================================================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('/tmp/remote_uploader.log')
    ]
)
logger = logging.getLogger(__name__)

# ============================================================
# æ ¸å¿ƒåŠŸèƒ½ç±»
# ============================================================

class LogReader:
    """å¼‚æ­¥æ—¥å¿—è¯»å–å™¨"""
    
    def __init__(self, log_dir: str, file_pattern: str):
        self.log_dir = Path(log_dir)
        self.file_pattern = file_pattern
        self.processed_files = set()
        
    def get_log_file_path(self, date: datetime) -> Path:
        """è·å–æŒ‡å®šæ—¥æœŸçš„æ—¥å¿—æ–‡ä»¶è·¯å¾„"""
        date_str = date.strftime('%Y-%m-%d')
        filename = self.file_pattern.format(date=date_str)
        return self.log_dir / filename
    
    def get_available_log_files(self, days_back: int = 7) -> List[Tuple[datetime, Path]]:
        """è·å–å¯ç”¨çš„æ—¥å¿—æ–‡ä»¶åˆ—è¡¨"""
        files = []
        today = datetime.now().date()
        
        for i in range(days_back + 1):
            date = datetime.combine(today - timedelta(days=i), datetime.min.time())
            file_path = self.get_log_file_path(date)
            
            if file_path.exists() and file_path.is_file():
                files.append((date, file_path))
                logger.debug(f"å‘ç°æ—¥å¿—æ–‡ä»¶: {file_path}")
        
        return sorted(files, key=lambda x: x[0])  # æŒ‰æ—¥æœŸæ’åº
    
    async def read_log_file(self, file_path: Path, processor) -> int:
        """å¼‚æ­¥è¯»å–æ—¥å¿—æ–‡ä»¶å¹¶äº¤ç»™å¤„ç†å™¨å¤„ç†"""
        if not file_path.exists():
            logger.warning(f"æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return 0
        
        logger.info(f"å¼€å§‹è¯»å–æ—¥å¿—æ–‡ä»¶: {file_path}")
        processed_lines = 0
        
        try:
            async with aiofiles.open(file_path, 'r', encoding='utf-8') as f:
                buffer = ""
                
                while True:
                    chunk = await f.read(READ_CHUNK_SIZE)
                    if not chunk:
                        break
                    
                    buffer += chunk
                    lines = buffer.split('\n')
                    buffer = lines[-1]  # ä¿ç•™æœ€åä¸€ä¸ªä¸å®Œæ•´çš„è¡Œ
                    
                    # å¤„ç†å®Œæ•´çš„è¡Œ
                    for line in lines[:-1]:
                        if line.strip():
                            await processor.process_line(line.strip())
                            processed_lines += 1
                            
                            # æ¯å¤„ç†ä¸€å®šæ•°é‡çš„è¡Œå°±è®©å‡ºæ§åˆ¶æƒ
                            if processed_lines % 1000 == 0:
                                await asyncio.sleep(0.001)
                
                # å¤„ç†æœ€åä¸€è¡Œ
                if buffer.strip():
                    await processor.process_line(buffer.strip())
                    processed_lines += 1
        
        except Exception as e:
            logger.error(f"è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return 0
        
        logger.info(f"å®Œæˆè¯»å–æ—¥å¿—æ–‡ä»¶: {file_path}, å¤„ç†äº† {processed_lines} è¡Œ")
        return processed_lines


class IPProcessor:
    """IPå¤„ç†å™¨ - è´Ÿè´£è§£æã€å»é‡å’Œç¼“å­˜IPæ•°æ®"""
    
    def __init__(self, botnet_type: str, cache_file: str):
        self.botnet_type = botnet_type
        self.cache_file = cache_file
        self.ip_cache: Set[str] = set()
        self.daily_ips: Dict[str, Set[str]] = defaultdict(set)  # æŒ‰æ—¥æœŸåˆ†ç»„çš„IP
        self.daily_ips_with_time: Dict[str, List[Dict]] = defaultdict(list)  # åŒ…å«æ—¶é—´æˆ³çš„IPæ•°æ®
        self.processed_count = 0
        self.duplicate_count = 0
        self.load_cache()
    
    def load_cache(self):
        """åŠ è½½IPç¼“å­˜ï¼ˆä»…ç”¨äºç»Ÿè®¡ï¼Œä¸ç”¨äºå»é‡ï¼‰"""
        try:
            if os.path.exists(self.cache_file):
                with open(self.cache_file, 'r') as f:
                    cache_data = json.load(f)
                
                # åŠ è½½æ‰€æœ‰å†å²IPï¼ˆç”¨äºç»Ÿè®¡æ˜¾ç¤ºï¼‰
                self.ip_cache = set()
                for ip_data in cache_data.get('ips', []):
                    self.ip_cache.add(ip_data['ip'])
                
                logger.info(f"åŠ è½½IPç¼“å­˜: {len(self.ip_cache)} ä¸ªIPï¼ˆä»…ç»Ÿè®¡ç”¨ï¼‰")
        except Exception as e:
            logger.warning(f"åŠ è½½IPç¼“å­˜å¤±è´¥: {e}")
            self.ip_cache = set()
    
    def save_cache(self):
        """ä¿å­˜IPç¼“å­˜"""
        try:
            cache_data = {
                'updated_at': datetime.now().isoformat(),
                'ips': [
                    {
                        'ip': ip,
                        'timestamp': datetime.now().isoformat()
                    }
                    for ip in self.ip_cache
                ]
            }
            
            with open(self.cache_file, 'w') as f:
                json.dump(cache_data, f, indent=2)
                
            logger.debug(f"ä¿å­˜IPç¼“å­˜: {len(self.ip_cache)} ä¸ªIP")
        except Exception as e:
            logger.error(f"ä¿å­˜IPç¼“å­˜å¤±è´¥: {e}")
    
    async def process_line(self, line: str):
        """å¤„ç†å•è¡Œæ—¥å¿—ï¼Œæå–IPåœ°å€å’Œæ—¶é—´æˆ³"""
        self.processed_count += 1
        
        # è§£ææ—¥å¿—æ ¼å¼: 2025-11-12 10:32:32,125.162.162.237
        ip_data = self.extract_ip_and_timestamp_from_line(line)
        
        if ip_data and self.is_valid_ip(ip_data['ip']):
            ip = ip_data['ip']
            log_date = ip_data['date']
            
            # åªåœ¨åŒä¸€å¤©å†…å»é‡ï¼Œè·¨æ—¥æœŸçš„é‡å¤IPä»éœ€è¦ä¸Šä¼ ä»¥æ›´æ–°updated_at
            if ip in self.daily_ips[log_date]:
                self.duplicate_count += 1
            else:
                # æ·»åŠ åˆ°å½“æ—¥é›†åˆï¼ˆåŒ…å«å®Œæ•´çš„IPæ•°æ®ï¼‰
                if log_date not in self.daily_ips_with_time:
                    self.daily_ips_with_time[log_date] = []
                
                self.daily_ips_with_time[log_date].append(ip_data)
                self.daily_ips[log_date].add(ip)
                
                # æ›´æ–°å…¨å±€ç¼“å­˜ï¼ˆç”¨äºç»Ÿè®¡ï¼Œä½†ä¸ç”¨äºå»é‡åˆ¤æ–­ï¼‰
                self.ip_cache.add(ip)
    
    def extract_ip_and_timestamp_from_line(self, line: str) -> Optional[Dict]:
        """ä»æ—¥å¿—è¡Œä¸­æå–IPåœ°å€å’Œæ—¶é—´æˆ³"""
        try:
            line = line.strip()
            if not line:
                return None
            
            # å°è¯•ä»è¡Œé¦–æå–æ—¶é—´æˆ³
            # æ”¯æŒæ ¼å¼ï¼š
            # 1. 2025/07/03 09:31:24 æ–°IPé¦–æ¬¡è¿æ¥: 180.254.163.108
            # 2. 2025-11-12 10:32:32,125.162.162.237
            # 3. 2025-11-12 10:32:32 å…¶ä»–æ–‡æœ¬ 125.162.162.237
            
            timestamp_str = None
            log_time = None
            
            # å°è¯•è§£æè¡Œé¦–çš„æ—¶é—´æˆ³ï¼ˆä¸¤ç§æ ¼å¼ï¼‰
            time_formats = [
                '%Y/%m/%d %H:%M:%S',  # 2025/07/03 09:31:24
                '%Y-%m-%d %H:%M:%S',  # 2025-11-12 10:32:32
            ]
            
            # æå–è¡Œé¦–çš„æ—¶é—´æˆ³å­—ç¬¦ä¸²ï¼ˆå‰19ä¸ªå­—ç¬¦ï¼‰
            if len(line) >= 19:
                potential_timestamp = line[:19]
                for fmt in time_formats:
                    try:
                        log_time = datetime.strptime(potential_timestamp, fmt)
                        timestamp_str = potential_timestamp
                        logger.debug(f"æˆåŠŸè§£ææ—¶é—´æˆ³: {timestamp_str} -> {log_time}")
                        break
                    except ValueError:
                        continue
            
            # å¦‚æœæ²¡æœ‰è§£æåˆ°æ—¶é—´æˆ³ï¼Œä½¿ç”¨å½“å‰æ—¶é—´
            if not log_time:
                logger.warning(f"æœªèƒ½ä»æ—¥å¿—è¡Œæå–æ—¶é—´æˆ³ï¼Œä½¿ç”¨å½“å‰æ—¶é—´: {line[:50]}...")
                log_time = datetime.now()
            
            # æå–IPåœ°å€
            ips = IP_REGEX.findall(line)
            if ips:
                # è¿‡æ»¤æ‰æ—¶é—´æˆ³ä¸­å¯èƒ½è¢«è¯¯è¯†åˆ«çš„æ•°å­—
                valid_ips = [ip for ip in ips if self.is_valid_ip(ip)]
                if valid_ips:
                    return {
                        'ip': valid_ips[0],
                        'timestamp': log_time.isoformat(),
                        'date': log_time.strftime('%Y-%m-%d'),
                        'botnet_type': self.botnet_type
                    }
            
            return None
        except Exception as e:
            logger.debug(f"æå–IPå’Œæ—¶é—´æˆ³å¤±è´¥: {line[:50]}... é”™è¯¯: {e}")
            return None
    
    def extract_ip_from_line(self, line: str) -> Optional[str]:
        """ä»æ—¥å¿—è¡Œä¸­æå–IPåœ°å€ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰"""
        ip_data = self.extract_ip_and_timestamp_from_line(line)
        return ip_data['ip'] if ip_data else None
    
    def is_valid_ip(self, ip: str) -> bool:
        """éªŒè¯IPåœ°å€æ˜¯å¦æœ‰æ•ˆ"""
        try:
            parts = ip.split('.')
            if len(parts) != 4:
                return False
            
            for part in parts:
                num = int(part)
                if num < 0 or num > 255:
                    return False
            
            # è¿‡æ»¤ç§æœ‰IPå’Œç‰¹æ®ŠIP
            if ip.startswith(('127.', '10.', '192.168.', '169.254.')):
                return False
            if ip.startswith('172.'):
                second_octet = int(parts[1])
                if 16 <= second_octet <= 31:
                    return False
            
            return True
        except:
            return False
    
    def get_new_ips_for_upload(self, max_count: int = None) -> List[Dict]:
        """è·å–éœ€è¦ä¸Šä¼ çš„æ–°IPæ•°æ®ï¼ˆåŒ…å«çœŸå®æ—¶é—´æˆ³ï¼‰"""
        all_new_ips = []
        
        # ä¼˜å…ˆä½¿ç”¨åŒ…å«æ—¶é—´æˆ³çš„æ•°æ®
        for date, ip_data_list in self.daily_ips_with_time.items():
            all_new_ips.extend(ip_data_list)
        
        # å¦‚æœæ²¡æœ‰æ—¶é—´æˆ³æ•°æ®ï¼Œå›é€€åˆ°æ—§æ ¼å¼ï¼ˆå…¼å®¹æ€§ï¼‰
        if not all_new_ips:
            for date, ips in self.daily_ips.items():
                for ip in ips:
                    all_new_ips.append({
                        'ip': ip,
                        'date': date,
                        'botnet_type': self.botnet_type,
                        'timestamp': datetime.now().isoformat()
                    })
        
        # é™åˆ¶æ•°é‡
        if max_count and len(all_new_ips) > max_count:
            return all_new_ips[:max_count]
        
        return all_new_ips
    
    def clear_uploaded_ips(self, uploaded_count: int):
        """æ¸…ç†å·²ä¸Šä¼ çš„IPï¼ˆåŒ…å«æ—¶é—´æˆ³æ•°æ®ï¼‰"""
        # ä¼˜å…ˆæ¸…ç†æ—¶é—´æˆ³æ•°æ®
        cleared_count = 0
        
        for date in list(self.daily_ips_with_time.keys()):
            ip_data_list = self.daily_ips_with_time[date]
            
            # æ¸…ç†æŒ‡å®šæ•°é‡çš„IPæ•°æ®
            while ip_data_list and cleared_count < uploaded_count:
                ip_data = ip_data_list.pop(0)
                ip = ip_data['ip']
                
                # åŒæ—¶ä»daily_ipsä¸­ç§»é™¤
                if date in self.daily_ips:
                    self.daily_ips[date].discard(ip)
                
                cleared_count += 1
            
            # å¦‚æœè¯¥æ—¥æœŸçš„IPæ•°æ®ä¸ºç©ºï¼Œåˆ é™¤è¯¥æ—¥æœŸ
            if not ip_data_list:
                del self.daily_ips_with_time[date]
            
            # å¦‚æœè¯¥æ—¥æœŸçš„IPé›†åˆä¸ºç©ºï¼Œåˆ é™¤è¯¥æ—¥æœŸ
            if date in self.daily_ips and not self.daily_ips[date]:
                del self.daily_ips[date]
            
            if cleared_count >= uploaded_count:
                break
        
        # å¦‚æœæ—¶é—´æˆ³æ•°æ®ä¸è¶³ï¼Œç»§ç»­æ¸…ç†æ™®é€šIPæ•°æ®ï¼ˆå…¼å®¹æ€§ï¼‰
        if cleared_count < uploaded_count:
            for date in list(self.daily_ips.keys()):
                ips_list = list(self.daily_ips[date])
                
                for ip in ips_list:
                    if cleared_count >= uploaded_count:
                        break
                        
                    self.daily_ips[date].discard(ip)
                    cleared_count += 1
                
                # å¦‚æœè¯¥æ—¥æœŸçš„IPé›†åˆä¸ºç©ºï¼Œåˆ é™¤è¯¥æ—¥æœŸ
                if not self.daily_ips[date]:
                    del self.daily_ips[date]
                
                if cleared_count >= uploaded_count:
                    break
        
        logger.info(f"æ¸…ç†å·²ä¸Šä¼ çš„IP: {cleared_count} ä¸ª")
    
    def get_stats(self) -> Dict:
        """è·å–å¤„ç†ç»Ÿè®¡"""
        total_new_ips = sum(len(ips) for ips in self.daily_ips.values())
        return {
            'processed_lines': self.processed_count,
            'duplicate_count': self.duplicate_count,
            'cached_ips': len(self.ip_cache),
            'new_ips_pending': total_new_ips
        }


class RemoteUploader:
    """è¿œç«¯ä¸Šä¼ å™¨ - è´Ÿè´£å°†å¤„ç†åçš„æ•°æ®ä¸Šä¼ åˆ°æœ¬åœ°æœåŠ¡å™¨"""
    
    def __init__(self):
        self.upload_count = 0
        self.error_count = 0
        self.session = None
    
    async def create_session(self):
        """åˆ›å»ºHTTPä¼šè¯"""
        if self.session is None:
            timeout = aiohttp.ClientTimeout(total=30)
            self.session = aiohttp.ClientSession(timeout=timeout)
    
    async def close_session(self):
        """å…³é—­HTTPä¼šè¯"""
        if self.session:
            await self.session.close()
            self.session = None
    
    async def upload_ips(self, ip_data: List[Dict]) -> bool:
        """å¼‚æ­¥ä¸Šä¼ IPæ•°æ®åˆ°æœ¬åœ°æœåŠ¡å™¨"""
        if not ip_data:
            return True
        
        await self.create_session()
        
        headers = {
            "Content-Type": "application/json",
            "X-API-Key": API_KEY
        }
        
        data = {
            "botnet_type": BOTNET_TYPE,
            "ip_data": ip_data,
            "source_ip": await self.get_local_ip()
        }
        
        for attempt in range(MAX_RETRIES):
            try:
                logger.info(f"ä¸Šä¼  {len(ip_data)} ä¸ªIP (å°è¯• {attempt + 1}/{MAX_RETRIES})")
                
                async with self.session.post(
                    API_ENDPOINT,
                    json=data,
                    headers=headers
                ) as response:
                    
                    if response.status == 200:
                        result = await response.json()
                        logger.info(f"âœ… ä¸Šä¼ æˆåŠŸ: {result.get('received_count', len(ip_data))} ä¸ªIP")
                        self.upload_count += result.get('received_count', len(ip_data))
                        return True
                        
                    elif response.status == 401:
                        logger.error("âŒ è®¤è¯å¤±è´¥: APIå¯†é’¥æ— æ•ˆ")
                        return False
                        
                    elif response.status == 403:
                        logger.error("âŒ æƒé™ä¸è¶³: IPæœªåœ¨ç™½åå•ä¸­")
                        return False
                        
                    else:
                        error_text = await response.text()
                        logger.warning(f"âš ï¸ ä¸Šä¼ å¤±è´¥ (HTTP {response.status}): {error_text}")
                        
            except aiohttp.ClientError as e:
                logger.warning(f"âš ï¸ ç½‘ç»œé”™è¯¯: {e}")
                
            except Exception as e:
                logger.error(f"âš ï¸ ä¸Šä¼ å¼‚å¸¸: {e}")
            
            # é‡è¯•å»¶è¿Ÿ
            if attempt < MAX_RETRIES - 1:
                logger.info(f"ç­‰å¾… {RETRY_DELAY} ç§’åé‡è¯•...")
                await asyncio.sleep(RETRY_DELAY)
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        logger.error(f"âŒ ä¸Šä¼ å¤±è´¥: å·²é‡è¯• {MAX_RETRIES} æ¬¡")
        self.error_count += 1
        return False
    
    async def get_local_ip(self) -> str:
        """è·å–æœ¬æœºIP"""
        try:
            # ä½¿ç”¨å¼‚æ­¥æ–¹å¼è·å–IP
            import socket
            loop = asyncio.get_event_loop()
            
            def _get_ip():
                s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
                s.connect(("8.8.8.8", 80))
                ip = s.getsockname()[0]
                s.close()
                return ip
            
            return await loop.run_in_executor(None, _get_ip)
        except:
            return "unknown"


class AsyncLogProcessor:
    """å¼‚æ­¥æ—¥å¿—å¤„ç†å™¨ - åè°ƒLogReaderã€IPProcessorå’ŒRemoteUploader"""
    
    def __init__(self):
        self.log_reader = LogReader(LOG_DIR, LOG_FILE_PATTERN)
        self.ip_processor = IPProcessor(BOTNET_TYPE, DUPLICATE_CACHE_FILE)
        self.uploader = RemoteUploader()
        self.state = self.load_state()
    
    def load_state(self) -> Dict:
        """åŠ è½½å¤„ç†çŠ¶æ€"""
        try:
            if os.path.exists(STATE_FILE):
                with open(STATE_FILE, 'r') as f:
                    state = json.load(f)
                    logger.info(f"åŠ è½½çŠ¶æ€: å·²å¤„ç†æ–‡ä»¶ {len(state.get('processed_files', []))} ä¸ª")
                    return state
        except Exception as e:
            logger.warning(f"åŠ è½½çŠ¶æ€å¤±è´¥: {e}")
        
        return {
            'processed_files': [],
            'last_upload_time': None,
            'total_processed': 0
        }
    
    def save_state(self):
        """ä¿å­˜å¤„ç†çŠ¶æ€"""
        try:
            with open(STATE_FILE, 'w') as f:
                json.dump(self.state, f, indent=2)
            logger.debug("ä¿å­˜çŠ¶æ€æˆåŠŸ")
        except Exception as e:
            logger.error(f"ä¿å­˜çŠ¶æ€å¤±è´¥: {e}")
    
    async def process_log_files(self):
        """å¤„ç†æ—¥å¿—æ–‡ä»¶"""
        # è·å–å¯ç”¨çš„æ—¥å¿—æ–‡ä»¶
        log_files = self.log_reader.get_available_log_files()
        
        if not log_files:
            logger.info("æ²¡æœ‰æ‰¾åˆ°æ—¥å¿—æ–‡ä»¶")
            return
        
        logger.info(f"å‘ç° {len(log_files)} ä¸ªæ—¥å¿—æ–‡ä»¶")
        
        # è¿‡æ»¤å·²å¤„ç†çš„æ–‡ä»¶
        processed_files = set(self.state.get('processed_files', []))
        new_files = [(date, path) for date, path in log_files 
                    if str(path) not in processed_files]
        
        if not new_files:
            logger.info("æ‰€æœ‰æ—¥å¿—æ–‡ä»¶éƒ½å·²å¤„ç†")
            return
        
        logger.info(f"éœ€è¦å¤„ç† {len(new_files)} ä¸ªæ–°æ—¥å¿—æ–‡ä»¶")
        
        # å¼‚æ­¥å¤„ç†æ¯ä¸ªæ–‡ä»¶
        for date, file_path in new_files:
            logger.info(f"å¤„ç†æ—¥å¿—æ–‡ä»¶: {file_path} (æ—¥æœŸ: {date.strftime('%Y-%m-%d')})")
            
            try:
                processed_lines = await self.log_reader.read_log_file(file_path, self.ip_processor)
                
                if processed_lines > 0:
                    # æ ‡è®°æ–‡ä»¶ä¸ºå·²å¤„ç†
                    self.state['processed_files'].append(str(file_path))
                    self.state['total_processed'] += processed_lines
                    
                    logger.info(f"å®Œæˆå¤„ç†: {file_path}, å¤„ç†äº† {processed_lines} è¡Œ")
                    
                    # ä¿å­˜çŠ¶æ€
                    self.save_state()
                    
            except Exception as e:
                logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
    
    async def upload_new_ips(self):
        """ä¸Šä¼ æ–°å‘ç°çš„IP"""
        new_ips = self.ip_processor.get_new_ips_for_upload(BATCH_SIZE)
        
        if not new_ips:
            logger.info("æ²¡æœ‰æ–°IPéœ€è¦ä¸Šä¼ ")
            return
        
        logger.info(f"å‡†å¤‡ä¸Šä¼  {len(new_ips)} ä¸ªæ–°IP")
        
        # ä¸Šä¼ IPæ•°æ®
        success = await self.uploader.upload_ips(new_ips)
        
        if success:
            # æ¸…ç†å·²ä¸Šä¼ çš„IP
            self.ip_processor.clear_uploaded_ips(len(new_ips))
            self.state['last_upload_time'] = datetime.now().isoformat()
            
            # ä¿å­˜IPç¼“å­˜å’ŒçŠ¶æ€
            self.ip_processor.save_cache()
            self.save_state()
            
            logger.info(f"ä¸Šä¼ å®Œæˆï¼Œç´¯è®¡ä¸Šä¼ : {self.uploader.upload_count} ä¸ªIP")
        else:
            logger.error("ä¸Šä¼ å¤±è´¥ï¼ŒIPæ•°æ®å°†åœ¨ä¸‹æ¬¡é‡è¯•")
    
    async def run_once(self):
        """æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„å¤„ç†æµç¨‹"""
        logger.info("-" * 80)
        logger.info("å¼€å§‹æ‰§è¡Œæ—¥å¿—å¤„ç†ä»»åŠ¡")
        
        try:
            # 1. å¤„ç†æ—¥å¿—æ–‡ä»¶
            await self.process_log_files()
            
            # 2. ä¸Šä¼ æ–°IP
            await self.upload_new_ips()
            
            # 3. æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            self.print_stats()
            
        except Exception as e:
            logger.error(f"å¤„ç†ä»»åŠ¡å¼‚å¸¸: {e}")
        
        logger.info("ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
    
    async def run_forever(self):
        """æŒç»­è¿è¡Œå¤„ç†å™¨"""
        logger.info("=" * 80)
        logger.info("å¼‚æ­¥æ—¥å¿—å¤„ç†å™¨å¯åŠ¨")
        logger.info("=" * 80)
        logger.info(f"ç›®æ ‡æœåŠ¡å™¨: {API_ENDPOINT}")
        logger.info(f"åƒµå°¸ç½‘ç»œç±»å‹: {BOTNET_TYPE}")
        logger.info(f"æ—¥å¿—ç›®å½•: {LOG_DIR}")
        logger.info(f"æ–‡ä»¶æ¨¡å¼: {LOG_FILE_PATTERN}")
        logger.info(f"å¤„ç†é—´éš”: {UPLOAD_INTERVAL} ç§’")
        logger.info(f"æ‰¹é‡å¤§å°: {BATCH_SIZE} ä¸ªIP")
        logger.info("=" * 80)
        
        try:
            while True:
                await self.run_once()
                
                # ç­‰å¾…ä¸‹æ¬¡æ‰§è¡Œ
                logger.info(f"ç­‰å¾… {UPLOAD_INTERVAL} ç§’åæ‰§è¡Œä¸‹æ¬¡å¤„ç†...")
                await asyncio.sleep(UPLOAD_INTERVAL)
                
        except KeyboardInterrupt:
            logger.info("\næ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
        except Exception as e:
            logger.error(f"å¤„ç†å™¨å¼‚å¸¸: {e}")
        finally:
            # æ¸…ç†èµ„æº
            await self.uploader.close_session()
            
            # æœ€ç»ˆç»Ÿè®¡
            logger.info("=" * 80)
            logger.info("å¤„ç†å™¨å·²åœæ­¢")
            self.print_stats()
            logger.info("=" * 80)
    
    def print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        ip_stats = self.ip_processor.get_stats()
        
        logger.info("ğŸ“Š å¤„ç†ç»Ÿè®¡:")
        logger.info(f"  å·²å¤„ç†è¡Œæ•°: {ip_stats['processed_lines']:,}")
        logger.info(f"  é‡å¤IPæ•°: {ip_stats['duplicate_count']:,}")
        logger.info(f"  ç¼“å­˜IPæ•°: {ip_stats['cached_ips']:,}")
        logger.info(f"  å¾…ä¸Šä¼ IP: {ip_stats['new_ips_pending']:,}")
        logger.info(f"  ç´¯è®¡ä¸Šä¼ : {self.uploader.upload_count:,}")
        logger.info(f"  é”™è¯¯æ¬¡æ•°: {self.uploader.error_count}")


# ============================================================
# å‘½ä»¤è¡Œæ¨¡å¼
# ============================================================

async def test_connection():
    """æµ‹è¯•è¿æ¥"""
    print("æµ‹è¯•è¿æ¥åˆ°æœ¬åœ°æœåŠ¡å™¨...")
    print(f"ç›®æ ‡: {API_ENDPOINT}")
    
    try:
        timeout = aiohttp.ClientTimeout(total=10)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            status_url = f"http://{LOCAL_SERVER_HOST}:{LOCAL_SERVER_PORT}/api/upload-status"
            
            async with session.get(status_url) as response:
                if response.status == 200:
                    data = await response.json()
                    print(f"âœ… è¿æ¥æˆåŠŸ!")
                    print(f"æœåŠ¡å™¨çŠ¶æ€: {data.get('api_status', 'unknown')}")
                    print(f"æœåŠ¡å™¨æ—¶é—´: {data.get('timestamp', 'unknown')}")
                    return True
                else:
                    print(f"âŒ è¿æ¥å¤±è´¥: HTTP {response.status}")
                    return False
                    
    except Exception as e:
        print(f"âŒ è¿æ¥å¤±è´¥: {e}")
        return False


async def test_upload():
    """æµ‹è¯•ä¸Šä¼ åŠŸèƒ½"""
    print("\næµ‹è¯•ä¸Šä¼ åŠŸèƒ½...")
    
    # æ¨¡æ‹ŸIPæ•°æ®
    test_ip_data = [{
        'ip': '1.2.3.4',
        'date': datetime.now().strftime('%Y-%m-%d'),
        'botnet_type': BOTNET_TYPE,
        'timestamp': datetime.now().isoformat()
    }]
    
    uploader = RemoteUploader()
    success = await uploader.upload_ips(test_ip_data)
    await uploader.close_session()
    
    if success:
        print("âœ… ä¸Šä¼ æµ‹è¯•æˆåŠŸ!")
        return True
    else:
        print("âŒ ä¸Šä¼ æµ‹è¯•å¤±è´¥!")
        return False


async def test_log_processing():
    """æµ‹è¯•æ—¥å¿—å¤„ç†åŠŸèƒ½"""
    print("\næµ‹è¯•æ—¥å¿—å¤„ç†åŠŸèƒ½...")
    
    processor = AsyncLogProcessor()
    
    # æ£€æŸ¥æ—¥å¿—æ–‡ä»¶
    log_files = processor.log_reader.get_available_log_files()
    if not log_files:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ—¥å¿—æ–‡ä»¶")
        print(f"è¯·æ£€æŸ¥æ—¥å¿—ç›®å½•: {LOG_DIR}")
        print(f"æ–‡ä»¶æ¨¡å¼: {LOG_FILE_PATTERN}")
        return False
    
    print(f"âœ… æ‰¾åˆ° {len(log_files)} ä¸ªæ—¥å¿—æ–‡ä»¶")
    for date, path in log_files:
        file_size = path.stat().st_size if path.exists() else 0
        print(f"  {date.strftime('%Y-%m-%d')}: {path} ({file_size:,} bytes)")
    
    return True


async def main_async():
    """å¼‚æ­¥ä¸»å‡½æ•°"""
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == "test":
            # æµ‹è¯•æ¨¡å¼
            print("=" * 80)
            print("  è¿œç«¯ä¸Šä¼ å™¨ - æµ‹è¯•æ¨¡å¼")
            print("=" * 80)
            
            # æµ‹è¯•è¿æ¥
            conn_ok = await test_connection()
            if not conn_ok:
                print("\nè¯·æ£€æŸ¥:")
                print("  1. LOCAL_SERVER_HOST æ˜¯å¦æ­£ç¡®ï¼Ÿ")
                print("  2. æœ¬åœ°æœåŠ¡å™¨æ˜¯å¦è¿è¡Œï¼Ÿ")
                print("  3. é˜²ç«å¢™æ˜¯å¦å¼€æ”¾ç«¯å£ï¼Ÿ")
                sys.exit(1)
            
            # æµ‹è¯•ä¸Šä¼ 
            upload_ok = await test_upload()
            if not upload_ok:
                print("\nè¯·æ£€æŸ¥:")
                print("  1. API_KEY æ˜¯å¦æ­£ç¡®ï¼Ÿ")
                print("  2. è¿œç«¯IPæ˜¯å¦åœ¨ç™½åå•ä¸­ï¼Ÿ")
                sys.exit(1)
            
            # æµ‹è¯•æ—¥å¿—å¤„ç†
            log_ok = await test_log_processing()
            if not log_ok:
                print("\nè¯·æ£€æŸ¥:")
                print("  1. LOG_DIR è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Ÿ")
                print("  2. æ—¥å¿—æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Ÿ")
                print("  3. LOG_FILE_PATTERN æ¨¡å¼æ˜¯å¦æ­£ç¡®ï¼Ÿ")
                sys.exit(1)
            
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥è¿è¡Œæ­£å¼æ¨¡å¼")
            print(f"\nå¯åŠ¨å‘½ä»¤: python {sys.argv[0]}")
            
        elif command == "once":
            # å•æ¬¡æ‰§è¡Œ
            processor = AsyncLogProcessor()
            await processor.run_once()
            await processor.uploader.close_session()
            
        else:
            print(f"æœªçŸ¥å‘½ä»¤: {command}")
            print(f"ç”¨æ³•:")
            print(f"  python {sys.argv[0]}       - æŒç»­è¿è¡Œ")
            print(f"  python {sys.argv[0]} test  - æµ‹è¯•è¿æ¥")
            print(f"  python {sys.argv[0]} once  - å•æ¬¡æ‰§è¡Œ")
    else:
        # æŒç»­è¿è¡Œæ¨¡å¼
        processor = AsyncLogProcessor()
        await processor.run_forever()


def main():
    """ä¸»å‡½æ•°"""
    try:
        asyncio.run(main_async())
    except KeyboardInterrupt:
        logger.info("ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()





