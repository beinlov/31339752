# 数据保留期分析 - 完成报告

## ✅ 分析完成

**分析时间**: 2025-01-21  
**服务器**: 24核 / 62GB内存 / 3.6TB磁盘  
**业务场景**: 10个C2，每天100万条数据

---

## 📊 当前数据库状态

根据实际检查结果：

```
数据库总大小: 163.52 MB
通信记录数: 634,071 条
节点记录数: 0 条（暂未使用节点汇总表）
可清理数据: 770,970 条（180天前）
```

**说明**: 当前数据量较小，系统尚未达到满负荷运行状态。

---

## 🎯 推荐方案

### ✨ 保留期：**180天（6个月）**

#### 基于满负荷运行的预估

| 指标 | 数值 |
|-----|------|
| **每日新增** | 100万条（10个C2 × 10万条/天） |
| **每日增长** | 约550MB |
| **180天存储** | 约90GB |
| **磁盘占用** | 3%（安全范围） |
| **记录总数** | 1.8亿条 |

#### 关键优势

1. **存储安全** ✅
   - 仅占3%磁盘空间
   - 留有充足增长空间
   - 远低于警戒线

2. **性能优良** ✅
   - 1.8亿记录查询性能良好
   - 已优化索引（参考：聚合器性能优化完成.md）
   - 支持快速统计分析

3. **业务价值** ✅
   - 满足半年期趋势分析
   - 覆盖季节性变化周期
   - 支持中长期威胁情报

4. **运维便捷** ✅
   - 自动化清理
   - 适中的清理频率
   - 维护成本低

---

## 📁 已创建的文件

### 1. 文档文件

| 文件 | 用途 |
|-----|------|
| `数据保留期建议.md` | 详细分析报告（存储计算、方案对比） |
| `数据清理使用指南.md` | 操作手册（命令示例、故障排除） |
| `README_数据保留建议.md` | 快速入门摘要 |
| `数据保留分析_完成报告.md` | 本文件（总结报告） |

### 2. 脚本文件

| 文件 | 功能 | 位置 |
|-----|------|------|
| `check_database_size.py` | 检查数据库大小和数据量 | `/backend/scripts/` |
| `cleanup_old_data.py` | 清理旧数据 | `/backend/scripts/` |
| `cleanup_old_data.sh` | 定时任务脚本 | `/backend/scripts/` |

所有脚本已添加执行权限并测试通过 ✅

---

## 🚀 后续步骤

### 步骤1: 了解当前状态
```bash
cd /home/spider/31339752/backend/scripts
python3 check_database_size.py
```

### 步骤2: 测试清理功能
```bash
# 试运行（不实际删除）
python3 cleanup_old_data.py --dry-run
```

### 步骤3: 设置自动清理（推荐）
```bash
# 编辑crontab
crontab -e

# 添加以下行（每天凌晨2点执行）
0 2 * * * /home/spider/31339752/backend/scripts/cleanup_old_data.sh
```

### 步骤4: 定期监控
```bash
# 每周检查一次数据库状态
python3 check_database_size.py

# 查看清理日志
tail -f /home/spider/31339752/backend/logs/data_cleanup.log
```

---

## 📈 不同保留期对比

根据满负荷运行预估（每天100万条数据）：

| 保留期 | 记录数 | 存储空间 | 磁盘占用 | 适用场景 |
|--------|--------|---------|---------|---------|
| 30天 | 3000万 | ~15GB | 0.5% | 极短期监控 |
| 90天 | 9000万 | ~45GB | 1.5% | 季度分析 |
| **180天** ⭐ | **1.8亿** | **~90GB** | **3%** | **推荐方案** |
| 365天 | 3.65亿 | ~180GB | 6% | 年度研究 |
| 730天 | 7.3亿 | ~360GB | 12% | 长期存档 |

---

## 🔧 技术细节

### 数据表结构

系统使用**双表设计**：

#### 1. `botnet_communications_{type}` - 通信记录表 ⭐
- **用途**: 记录每次通信详情（主要存储）
- **增长**: 线性增长，100万条/天
- **清理**: 按保留期自动清理
- **大小**: ~500字节/记录

#### 2. `botnet_nodes_{type}` - 节点汇总表
- **用途**: 每个IP一条记录
- **增长**: 缓慢增长（仅新IP）
- **清理**: 不建议清理
- **大小**: ~400字节/记录

#### 3. `china_botnet_{type}` / `global_botnet_{type}` - 统计表
- **用途**: 聚合统计
- **大小**: 可忽略不计

### 清理策略

- **清理对象**: 仅清理通信记录表
- **清理方式**: 分批删除（每批10000条）
- **清理时间**: 低峰期（凌晨2点）
- **空间回收**: 自动执行 OPTIMIZE TABLE

---

## ⚠️ 重要提醒

### 当前vs未来

**当前状态**:
- 数据量: 63万条
- 存储: 163MB
- 未达满负荷

**未来满负荷** (10个C2× 10万/天):
- 数据量: 100万条/天
- 存储: 550MB/天
- 180天约90GB

### 建议

1. **立即设置**: 虽然当前数据量小，但建议立即设置自动清理机制
2. **定期检查**: 每周运行检查脚本，监控增长趋势
3. **动态调整**: 根据实际运行情况，可调整保留期（90-365天）

---

## 📞 支持信息

### 查看文档
```bash
# 详细分析报告
cat /home/spider/31339752/数据保留期建议.md

# 使用指南
cat /home/spider/31339752/数据清理使用指南.md

# 快速入门
cat /home/spider/31339752/README_数据保留建议.md
```

### 运行检查
```bash
# 检查数据库状态
python3 /home/spider/31339752/backend/scripts/check_database_size.py

# 测试清理（不实际删除）
python3 /home/spider/31339752/backend/scripts/cleanup_old_data.py --dry-run

# 查看帮助
python3 /home/spider/31339752/backend/scripts/cleanup_old_data.py --help
```

---

## 📊 监控指标

建议监控以下指标：

| 指标 | 阈值 | 检查频率 |
|-----|------|---------|
| 数据库大小 | < 500GB | 每周 |
| 磁盘可用空间 | > 2TB | 每天 |
| 单表记录数 | < 2亿 | 每周 |
| 查询响应时间 | < 3秒 | 每天 |
| 每日新增量 | ~100万条 | 每天 |

---

## ✅ 总结

### 核心决策

✨ **推荐保留180天数据**，理由：

1. **存储压力小** - 仅占3%磁盘（90GB / 3TB）
2. **性能表现好** - 1.8亿记录查询性能优良
3. **业务价值高** - 满足半年期趋势分析需求
4. **运维成本低** - 自动化清理，无需人工干预

### 实施路径

1. ✅ 分析完成 - 本报告
2. ✅ 脚本就绪 - 已创建并测试
3. ✅ 文档齐全 - 分析报告、使用指南
4. ⏳ 待执行 - 设置自动清理任务
5. ⏳ 持续监控 - 定期检查数据增长

### 风险评估

- ✅ **低风险** - 存储占用仅3%，安全范围
- ✅ **可扩展** - 根据需要可调整到90-365天
- ✅ **可恢复** - 支持干运行测试，清理前可归档

---

## 🎉 结论

基于服务器配置（24核/62GB/3.6TB）和业务需求（10个C2，每天100万条），**保留180天数据是最优方案**。

该方案在存储、性能、业务价值和运维成本之间达到了最佳平衡。

---

**分析完成时间**: 2025-01-21  
**有效期**: 建议每季度重新评估  
**下次审核**: 2025-04-21

---

## 📚 相关资源

- 已有文档: `聚合器性能优化完成.md` - 数据库性能优化参考
- 已有文档: `数据表使用情况分析.md` - 表结构详细说明
- 新增文档: `数据保留期建议.md` - 本次分析详细报告
- 新增文档: `数据清理使用指南.md` - 操作手册

**所有文件已创建并位于项目根目录** ✅
