# 统计聚合器使用指南

## 🎯 功能说明

统计聚合器解决了**数据流断层**的问题：

### 问题
- 日志处理器将数据写入 `botnet_nodes_mozi`（原始节点表）
- 前端从 `china_botnet_mozi` 和 `global_botnet_mozi`（统计表）读取数据
- **中间缺少了聚合步骤！** → 导致前端无数据显示

### 解决方案
统计聚合器定期（每30分钟）从节点表聚合统计数据到展示表。

## 📊 数据流向图

```
┌─────────────────────────────────────────────────────────────┐
│  远端蜜罐/传感器                                              │
└─────────────────────────────────────────────────────────────┘
                         │
                         ↓ (HTTP POST 上传日志)
┌─────────────────────────────────────────────────────────────┐
│  本地服务器: logs/mozi/2025-10-31.txt                        │
└─────────────────────────────────────────────────────────────┘
                         │
                         ↓ (日志处理器监控读取)
┌─────────────────────────────────────────────────────────────┐
│  数据库: botnet_nodes_mozi (原始节点表)                       │
│  - 存储每个IP的详细信息                                        │
│  - 包含时间、地理位置、ISP、ASN等                              │
└─────────────────────────────────────────────────────────────┘
                         │
                         ↓ 【统计聚合器 - 每30分钟】← 你在这里！
         ┌───────────────┴────────────────┐
         ↓                                 ↓
┌──────────────────────┐         ┌──────────────────────┐
│ china_botnet_mozi    │         │ global_botnet_mozi   │
│ (中国省市统计表)      │         │ (全球国家统计表)      │
│ - 按省市分组          │         │ - 按国家分组          │
│ - 统计节点数量        │         │ - 统计节点数量        │
└──────────────────────┘         └──────────────────────┘
         │                                 │
         └───────────────┬────────────────┘
                         ↓
┌─────────────────────────────────────────────────────────────┐
│  前端展示                                                     │
│  - 地图上的节点分布                                           │
│  - 左侧省市统计                                              │
│  - 全球感染分布                                              │
└─────────────────────────────────────────────────────────────┘
```

## 🚀 快速开始

### 步骤1: 测试聚合器

```bash
cd backend
python test_aggregator.py
```

**预期输出：**
```
============================================================
  统计聚合器功能测试
============================================================

============================================================
测试 1: 数据库连接
============================================================
✅ 数据库连接成功
   MySQL 版本: 8.0.12
   当前数据库: botnet

============================================================
测试 2: 检查节点表
============================================================
✅ botnet_nodes_mozi      -    150 条记录
✅ botnet_nodes_asruex    -    320 条记录
...

============================================================
测试 3: 执行聚合测试
============================================================
正在聚合 mozi 数据...
✅ 聚合成功
   节点数: 150
   中国统计: 25 条
   全球统计: 8 条

============================================================
测试 4: 检查统计表
============================================================
✅ china_botnet_mozi      -     25 条记录

   Top 5 省市:
     北京 - 北京: 45
     上海 - 上海: 32
     广东 - 深圳: 28
     ...

✅ global_botnet_mozi     -      8 条记录

   Top 5 国家:
     中国: 150
     美国: 45
     ...

============================================================
测试总结
============================================================
✅ 通过 - 数据库连接
✅ 通过 - 节点表检查
✅ 通过 - 聚合功能
✅ 通过 - 统计表检查

总计: 4/4 通过

🎉 所有测试通过！统计聚合器工作正常。
```

### 步骤2: 启动聚合器（三种方式任选其一）

#### 方式A: 使用启动脚本（推荐）

**Windows:**
```bash
cd backend
start_aggregator.bat
```

**Linux/Mac:**
```bash
cd backend
chmod +x start_aggregator.sh
./start_aggregator.sh
```

#### 方式B: 直接运行

```bash
cd backend
python stats_aggregator/aggregator.py daemon 30
```

#### 方式C: 一键启动所有服务

**Windows:**
```bash
# 在项目根目录
start_all_services.bat
```

**Linux/Mac:**
```bash
# 在项目根目录
chmod +x start_all_services.sh
./start_all_services.sh
```

### 步骤3: 验证效果

1. **查看日志**
   ```bash
   # Linux/Mac
   tail -f backend/stats_aggregator.log
   
   # Windows (PowerShell)
   Get-Content backend\stats_aggregator.log -Wait -Tail 50
   ```

2. **检查数据库**
   ```sql
   mysql -u root -p123456 botnet
   
   -- 查看统计表
   SELECT * FROM china_botnet_mozi ORDER BY infected_num DESC LIMIT 10;
   SELECT * FROM global_botnet_mozi ORDER BY infected_num DESC LIMIT 10;
   ```

3. **访问前端**
   - 刷新浏览器
   - 检查地图是否显示节点
   - 检查左侧省市统计是否有数据

## ⚙️ 配置说明

### 修改聚合间隔

编辑对应脚本中的时间参数（单位：分钟）：

**快速调试（5分钟）：**
```bash
python stats_aggregator/aggregator.py daemon 5
```

**生产环境（30分钟）：**
```bash
python stats_aggregator/aggregator.py daemon 30
```

**低峰期聚合（60分钟）：**
```bash
python stats_aggregator/aggregator.py daemon 60
```

### 只聚合特定僵尸网络

```bash
# 单次聚合
python stats_aggregator/aggregator.py once mozi
python stats_aggregator/aggregator.py once asruex

# 守护进程模式（需要修改代码）
# 编辑 backend/stats_aggregator/aggregator.py
# 修改 BOTNET_TYPES 列表
```

## 📁 文件结构

```
backend/
├── stats_aggregator/
│   ├── __init__.py
│   ├── aggregator.py           # 主程序
│   ├── config.yaml             # 配置文件
│   └── README.md               # 详细文档
├── start_aggregator.bat        # Windows启动脚本
├── start_aggregator.sh         # Linux/Mac启动脚本
├── test_aggregator.py          # 测试脚本
└── stats_aggregator.log        # 运行日志

根目录/
├── start_all_services.bat      # 一键启动所有服务(Windows)
├── start_all_services.sh       # 一键启动所有服务(Linux/Mac)
└── stop_all_services.sh        # 停止所有服务(Linux/Mac)
```

## 🐛 常见问题排查

### Q1: 前端还是没有数据？

**检查清单：**

1. ✅ 聚合器是否在运行？
   ```bash
   # 查看日志
   cat backend/stats_aggregator.log
   
   # 查看进程
   # Windows: 任务管理器
   # Linux: ps aux | grep aggregator
   ```

2. ✅ 节点表是否有数据？
   ```sql
   SELECT COUNT(*) FROM botnet_nodes_mozi;
   ```

3. ✅ 统计表是否有数据？
   ```sql
   SELECT COUNT(*) FROM china_botnet_mozi;
   SELECT COUNT(*) FROM global_botnet_mozi;
   ```

4. ✅ 后端API是否正常？
   ```bash
   curl http://localhost:8000/api/province-amounts
   ```

5. ✅ 浏览器是否有缓存？
   - 按 Ctrl+F5 强制刷新
   - 或清除浏览器缓存

### Q2: 聚合器报错 "Table doesn't exist"

**原因：** 节点表不存在

**解决：**
1. 确保日志处理器已运行
2. 确保有日志文件被处理
3. 手动检查：
   ```sql
   SHOW TABLES LIKE 'botnet_nodes_%';
   ```

### Q3: 统计表数据为0

**原因：** 节点表为空

**解决：**
1. 检查日志文件是否存在：
   ```bash
   ls backend/logs/mozi/
   ```

2. 检查日志处理器是否运行：
   ```bash
   cat backend/log_processor.log
   ```

3. 测试上传接口：
   ```bash
   python test_upload.py
   ```

### Q4: 想立即看到效果，不想等30分钟

**解决：** 手动执行一次聚合

```bash
cd backend
python stats_aggregator/aggregator.py once
```

这会立即聚合所有数据，然后可以刷新前端查看效果。

## 📊 系统架构总览

```
┌─────────────────────────────────────────────────────────────┐
│                     僵尸网络监控系统                          │
└─────────────────────────────────────────────────────────────┘

【组件1: FastAPI 后端】 (backend/main.py)
  - 提供API接口给前端
  - 处理日志上传请求
  - 端口: 8000

【组件2: 日志处理器】 (backend/log_processor/main.py)
  - 监控 logs/ 目录
  - 解析日志文件
  - 写入 botnet_nodes_{type} 表

【组件3: 统计聚合器】 (backend/stats_aggregator/aggregator.py) ← 新增！
  - 定时聚合统计数据
  - 从节点表 → 统计表
  - 间隔: 30分钟（可配置）

【组件4: 前端】 (fronted/)
  - 从统计表读取数据
  - 可视化展示
  - 端口: 通常 3000 或 8080
```

## 🎯 最佳实践

### 开发环境
- 聚合间隔：**5分钟**（快速看到效果）
- 日志级别：DEBUG
- 手动触发：频繁使用 `once` 模式

### 生产环境
- 聚合间隔：**30分钟**（平衡实时性和性能）
- 日志级别：INFO
- 使用守护进程模式
- 监控日志文件
- 设置日志轮转

### 性能优化
- 如果数据量 < 10万：使用默认配置
- 如果数据量 > 10万：考虑增加间隔到60分钟
- 如果数据量 > 100万：考虑在低峰期聚合（凌晨）

## 🔄 完整数据流测试

从头到尾测试整个数据流：

```bash
# 1. 启动所有服务
./start_all_services.sh  # 或 start_all_services.bat

# 2. 上传测试日志
python test_upload.py

# 3. 等待日志处理器处理（几秒钟）
tail -f backend/log_processor.log

# 4. 手动触发聚合（或等待30分钟）
cd backend
python stats_aggregator/aggregator.py once

# 5. 测试API
curl http://localhost:8000/api/province-amounts

# 6. 访问前端查看
# 浏览器打开前端地址，按 Ctrl+F5 强制刷新
```

## 📞 技术支持

遇到问题？按以下顺序排查：

1. **查看日志**
   ```bash
   cat backend/stats_aggregator.log
   cat backend/log_processor.log
   cat backend/main.log
   ```

2. **运行测试**
   ```bash
   python backend/test_aggregator.py
   python test_api_fix.py
   python test_upload.py
   ```

3. **检查数据库**
   ```sql
   -- 检查表
   SHOW TABLES;
   
   -- 检查数据
   SELECT COUNT(*) FROM botnet_nodes_mozi;
   SELECT COUNT(*) FROM china_botnet_mozi;
   SELECT COUNT(*) FROM global_botnet_mozi;
   ```

4. **检查进程**
   ```bash
   # Linux/Mac
   ps aux | grep python
   
   # Windows
   # 任务管理器 → 详细信息 → 查找 python.exe
   ```

## ✅ 完成检查清单

部署完成后，确认以下项目都正常：

- [ ] 数据库连接正常
- [ ] 节点表存在且有数据
- [ ] 统计表存在且有数据
- [ ] 聚合器守护进程在运行
- [ ] 日志文件有新内容
- [ ] API返回数据（不是空或错误）
- [ ] 前端显示地图节点
- [ ] 前端显示省市统计
- [ ] 前端显示全球分布

全部打勾？**恭喜！系统已成功部署！** 🎉

